{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19814,
     "status": "ok",
     "timestamp": 1768448289196,
     "user": {
      "displayName": "dataarch engineering",
      "userId": "08951085103757294492"
     },
     "user_tz": 360
    },
    "id": "M98JkueBuxF7",
    "outputId": "bf5446fa-b631-41e1-8c75-d84e0c244b80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22330,
     "status": "ok",
     "timestamp": 1768448313872,
     "user": {
      "displayName": "dataarch engineering",
      "userId": "08951085103757294492"
     },
     "user_tz": 360
    },
    "id": "mADkIAqVt3Ip",
    "outputId": "dba4bf0f-eb61-468e-8a9a-693520029dc2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapter dir: /content/drive/MyDrive/slm-hosting-playbook-artifacts/live_backup/gemma-3-1b-it-lora-20260114-034307\n",
      "adapter_config exists: True\n",
      "adapter_model exists: True\n",
      "User: Explain monopsony in simple terms with a labor market example.\n",
      "Assistant: Monopsony is a market structure where one or a few companies control a significant portion of the market, making it difficult for smaller companies to compete. In the labor market, this can happen when a few large companies have the power to hire and fire workers, or when a small number of companies control a large portion of the industry. This can lead to low wages, fewer job opportunities, and less job security for workers.\n",
      "\n",
      "Example: Let's say there are only three companies in the food processing industry. If one of these companies is acquired by a larger company, it could gain control over\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# HF auth (Gemma is gated)\n",
    "login(token=os.environ[\"HF_TOKEN\"])\n",
    "\n",
    "BASE_MODEL_ID = \"google/gemma-3-1b-it\"\n",
    "ADAPTER_DIR = Path(\"/content/drive/MyDrive/slm-hosting-playbook-artifacts/live_backup/gemma-3-1b-it-lora-20260114-034307\").resolve()\n",
    "\n",
    "# 0) Hard verify adapter files exist locally\n",
    "print(\"Adapter dir:\", ADAPTER_DIR)\n",
    "print(\"adapter_config exists:\", (ADAPTER_DIR / \"adapter_config.json\").exists())\n",
    "print(\"adapter_model exists:\", (ADAPTER_DIR / \"adapter_model.safetensors\").exists())\n",
    "assert (ADAPTER_DIR / \"adapter_config.json\").exists(), \"Missing adapter_config.json in adapter dir\"\n",
    "assert (ADAPTER_DIR / \"adapter_model.safetensors\").exists(), \"Missing adapter_model.safetensors in adapter dir\"\n",
    "\n",
    "# 1) Load base model + tokenizer\n",
    "tok = AutoTokenizer.from_pretrained(BASE_MODEL_ID, use_fast=True)\n",
    "base = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_ID,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# 2) Attach adapter (force local path string)\n",
    "model = PeftModel.from_pretrained(base, str(ADAPTER_DIR), is_trainable=False)\n",
    "model.eval()\n",
    "\n",
    "prompt = \"User: Explain monopsony in simple terms with a labor market example.\\nAssistant:\"\n",
    "inputs = tok(prompt, return_tensors=\"pt\")\n",
    "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=120,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "\n",
    "print(tok.decode(out[0], skip_special_tokens=True))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPkc8dLQhwCYhLtlnWCbrwf",
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
